{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f494fb3",
   "metadata": {},
   "source": [
    "# COMP3610 Assignment 1\n",
    "\n",
    "- **Name:** Sonali Maharaj\n",
    "- **Student ID:** 816034459\n",
    "- **Course:** COMP3610  \n",
    "- **Assignment:** Assignment 1  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac09002",
   "metadata": {},
   "source": [
    "# Part 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d19dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping: data\\raw\\yellow_tripdata_2024-01.parquet\n",
      "File already exists, skipping: data\\raw\\taxi_zone_lookup.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Programmatically download the files\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# Create raw data directory if it doesn't exist\n",
    "RAW_DIR = Path(\"data/raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Required files\n",
    "FILES = [\n",
    "    (\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\",\n",
    "        RAW_DIR / \"yellow_tripdata_2024-01.parquet\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\",\n",
    "        RAW_DIR / \"taxi_zone_lookup.csv\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "def download_file(url, output_path, chunk_size=1024 * 1024):\n",
    "    \"\"\"\n",
    "    Downloads a file from a URL and saves it locally.\n",
    "    Uses streaming to handle large files efficiently.\n",
    "    \"\"\"\n",
    "    print(f\"\\nDownloading: {url}\")\n",
    "\n",
    "    with requests.get(url, stream=True, timeout=60) as response:\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "    # Validation check\n",
    "    if not output_path.exists() or output_path.stat().st_size == 0:\n",
    "        raise RuntimeError(f\"Download failed or file is empty: {output_path}\")\n",
    "\n",
    "    print(f\"Saved to: {output_path}\")\n",
    "    print(f\"File size: {output_path.stat().st_size / 1e6:.2f} MB\")\n",
    "\n",
    "\n",
    "# Download both required files\n",
    "for url, path in FILES:\n",
    "    if path.exists() and path.stat().st_size > 0:\n",
    "        print(f\"File already exists, skipping: {path}\")\n",
    "    else:\n",
    "        download_file(url, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6764f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Passed\n",
      "Total rows: 2,964,624\n",
      "Total columns: 19\n",
      "\n",
      "--- Dataset Summary ---\n",
      "shape: (9, 20)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ statistic ┆ VendorID  ┆ tpep_pick ┆ tpep_drop ┆ … ┆ improveme ┆ total_amo ┆ congestio ┆ Airport_ │\n",
      "│ ---       ┆ ---       ┆ up_dateti ┆ off_datet ┆   ┆ nt_surcha ┆ unt       ┆ n_surchar ┆ fee      │\n",
      "│ str       ┆ f64       ┆ me        ┆ ime       ┆   ┆ rge       ┆ ---       ┆ ge        ┆ ---      │\n",
      "│           ┆           ┆ ---       ┆ ---       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64      │\n",
      "│           ┆           ┆ str       ┆ str       ┆   ┆ f64       ┆           ┆ f64       ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ count     ┆ 2.964624e ┆ 2964624   ┆ 2964624   ┆ … ┆ 2.964624e ┆ 2.964624e ┆ 2.824462e ┆ 2.824462 │\n",
      "│           ┆ 6         ┆           ┆           ┆   ┆ 6         ┆ 6         ┆ 6         ┆ e6       │\n",
      "│ null_coun ┆ 0.0       ┆ 0         ┆ 0         ┆ … ┆ 0.0       ┆ 0.0       ┆ 140162.0  ┆ 140162.0 │\n",
      "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ mean      ┆ 1.754204  ┆ 2024-01-1 ┆ 2024-01-1 ┆ … ┆ 0.975632  ┆ 26.801505 ┆ 2.256122  ┆ 0.141161 │\n",
      "│           ┆           ┆ 7 00:46:3 ┆ 7 01:02:1 ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 6.431093  ┆ 3.208130  ┆   ┆           ┆           ┆           ┆          │\n",
      "│ std       ┆ 0.43259   ┆ null      ┆ null      ┆ … ┆ 0.218364  ┆ 23.385577 ┆ 0.823275  ┆ 0.487624 │\n",
      "│ min       ┆ 1.0       ┆ 2002-12-3 ┆ 2002-12-3 ┆ … ┆ -1.0      ┆ -900.0    ┆ -2.5      ┆ -1.75    │\n",
      "│           ┆           ┆ 1         ┆ 1         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 22:59:39  ┆ 23:05:41  ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 25%       ┆ 2.0       ┆ 2024-01-0 ┆ 2024-01-0 ┆ … ┆ 1.0       ┆ 15.38     ┆ 2.5       ┆ 0.0      │\n",
      "│           ┆           ┆ 9         ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 15:59:20  ┆ 16:16:23  ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 50%       ┆ 2.0       ┆ 2024-01-1 ┆ 2024-01-1 ┆ … ┆ 1.0       ┆ 20.1      ┆ 2.5       ┆ 0.0      │\n",
      "│           ┆           ┆ 7         ┆ 7         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 10:45:38  ┆ 11:03:52  ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 75%       ┆ 2.0       ┆ 2024-01-2 ┆ 2024-01-2 ┆ … ┆ 1.0       ┆ 28.56     ┆ 2.5       ┆ 0.0      │\n",
      "│           ┆           ┆ 4         ┆ 4         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 18:23:52  ┆ 18:40:29  ┆   ┆           ┆           ┆           ┆          │\n",
      "│ max       ┆ 6.0       ┆ 2024-02-0 ┆ 2024-02-0 ┆ … ┆ 1.0       ┆ 5000.0    ┆ 2.5       ┆ 1.75     │\n",
      "│           ┆           ┆ 1         ┆ 2         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ 00:01:15  ┆ 13:56:52  ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Validation\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path \n",
    "\n",
    "PARQUET_PATH = Path(\"data/raw/yellow_tripdata_2024-01.parquet\")\n",
    "\n",
    "# Check file exists \n",
    "if not PARQUET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing file: {PARQUET_PATH}. Run the download step first.\")\n",
    "\n",
    "# Load dataset \n",
    "lf = pl.scan_parquet(str(PARQUET_PATH))\n",
    "schema = lf.schema\n",
    "actual_columns = list(schema.keys())\n",
    "\n",
    "# Expected columns \n",
    "EXPECTED_COLUMNS = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"tip_amount\",\n",
    "    \"total_amount\",\n",
    "    \"payment_type\",\n",
    "]\n",
    "\n",
    "DATETIME_COLUMNS = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "]\n",
    "\n",
    "# a) Verify required columns exist \n",
    "missing_columns = [col for col in EXPECTED_COLUMNS if col not in actual_columns]\n",
    "\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Validation failed: Missing required columns: {missing_columns}\")\n",
    "\n",
    "# b) Check datetime columns are correct type\n",
    "for col in DATETIME_COLUMNS:\n",
    "    if schema[col] != pl.Datetime:\n",
    "        raise TypeError(f\"Validation failed: Column '{col}' is not datetime type.\")\n",
    "\n",
    "# c) Report row count and summary \n",
    "row_count = lf.select(pl.len()).collect().item()\n",
    "\n",
    "print(\"Validation Passed\")\n",
    "print(f\"Total rows: {row_count:,}\")\n",
    "print(f\"Total columns: {len(actual_columns)}\")\n",
    "\n",
    "# Print summary statistics \n",
    "df = lf.collect()\n",
    "print(\"\\n--- Dataset Summary ---\")\n",
    "print(df.describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
